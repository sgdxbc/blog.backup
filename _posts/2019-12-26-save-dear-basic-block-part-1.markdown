---
title: 拯救基本块大冒险！第一话
date: 2019-12-26 12:24
categories: weaver
tags: 优化 重构 算法 galgame 不记下来明天就忘了
toc: true
---

在[上一篇文章]({% post_url 2019-12-24-how-to-finish-optimizing-with-reasonable-memory-consumption %})中我揭示了基本块优化的最终目的，和（有可能）解决其内存消耗过高的思路——将一些条件分支保持为「折叠」状态，而不是成为基本块的分割线。为了便于说明，我将必须被展开融入基本块数据结构的条件分支称为`Choice`，而可以作为普通的指令滥竽充数的条件分支称为`If`。

## 整体思路

在开始优化冒险之前，我决定比较高度的概括一下基本块优化的整体思路，这是任何优化都不应该改变的基础。

我们要优化的程序中没有循环结构，因此可以将其执行过程比作galgame的游戏流程。如果我们可以在允许的程度内尽量早的完成所有的路线选择，我们接下来就可以双手离开键盘，一直看剧情一直爽（？）了。在这个类比中，`Choice`就对应了gal中真正会影响游戏结局的选择，而`If`就是那些只是为了丰富游戏内容，实际上不管怎么选都殊途同归的选择。

接下来就让我们开始我们的优化之旅吧。

## 基本块的惰性展开

上篇文章一开始的「内存耗尽图」是在整个程序执行的第一个阶段——构建基本快时截取的，因此，且不说运行效率，如果我们想要把这个程序执行完，最起码有一件事是确定的：我们绝不能把所有的`If`都当作`Choice`对待了。

那么，（一开始）把`Choice`都当作`If`怎么样？如果我们在优化的过程中发现某个`If`有可能把一个优化的机会隐藏起来了，再就地将其转为`Choice`，这样如何呢？

如果想要这样做，首先要回答一个问题：你是怎么知道「优化的机会」在哪里的。如果所有的`Create`和`Destroy`都（分别）在某个`If`的内部，从优化过程一开始就始终处于被隐藏的状态，那么我想我们的优化程序是没有任何理由去使其重见天日的。

因此，我为`Command`引入了一种标记。`Command`是一种特殊的`SetValue`，每条命令都有一个提供者和一列参数，执行这个命令就是对提供者的一次写入（是的，提供者也是一个寄存器），**只有命令能成为被优化的目标**。除此之外，命令还有一个特性：它**一定**不会为常量分析提供任何有用的信息。我们认为能够提供命令的寄存器，其所拥有的值不可能是一个常量，事实上，这个值仅仅是对于其内部状态的某种抽象。命令的这种特性在（很）后面会用得上。

在优化过程开始之前，一个扫描程序会首先检查指令序列（这时还没有将其转化为基本块），并且递归地检查每一个条件分支的真假子序列。一旦发现了一条被打了标记的命令，那么**包裹它的每一层`If`**都会被重写为`Choice`。这种由下至上的贯通是保证被优化的命令能够在优化过程中被注意到的唯一方式。

----

好了，现在我们可以保证「优化的机会」的来源在我们的视线范围内了，那么我们又该怎么确定一个`If`块具有隐藏优化机会的嫌疑呢？一个`If`是否被展开，受影响最大的就是条件分支重定位算法。比如

```c
x = y;
if (y == 1) {
    y = 2;
    z = 2;
}
if (z == 1) {
    x = 3;
}
```

如果两个`if`都是展开的，那么通过分析我们可以发现`x = y`所更新的`x`的值与这两个`if`的判断条件都没有关系，从而可以一直到两个`if`都判断完了再执行

```c
if (y == 1) {
    z = 2;
    if (z == 1) {  // 事实上这个分支接下来会被常量分析消灭
        x = y;
        y = 2;
        x = 3;
    }  // 其他
```

但是如果第一个`if`没有展开呢？如果这个`if`被当作了一条普通的指令，那么我们对它的分析就会得出结论：这是一条读`y`，写`y`和`z`的指令。的确，如果条件判断的结果为假，那么它实际上不会写`y`和`z`，但是我们无法确认这一点。在这种分析的基础上，我们会发现第二个`if`的判断条件依赖与这条语句（写后读），而这条语句又依赖与`x = y`（读后写），于是，原本可以在两个`if`之后再执行的`x = y`被「卡」在了原地。

如何识别类似于上面例子中第一个`if`这种嫌疑人呢？事实上，只要一个`if`出现在了基本块判断条件的依赖中，它就必然有着隐藏优化的嫌疑。就像上面的例子中一样，真正被判断条件所依赖的其实只有`z = 2`这一个赋值而已，然而包含它的`if`语句的不透明性将事态扩展到了与`y`有关的程度，从而隐藏了重要的信息——和`y`有关的语句其实都可以在下一个基本块中再执行。

因此，惰性展开基本块的原则就可以明确为：在条件分支重定位过程中，分析完基本块条件判断的依赖以后，检查其依赖的所有语句中有没有`If`，如果有，那么它将被认定为一个`Choice`，当前基本块将会以它为分界线被就地展开为三个基本块——`Choice`之前、`Choice`的真假分支各一个，（这事实上也就使得原当前基本块之后的所有基本块全部被复制成两份），然后在这些新的基本块上重新执行条件分支重定位算法。

## 两种读写依赖维护算法

经过上面的改良以后，我们得到了两个好消息：初始化（创建基本块）的过程可以在一瞬间完成——因为实际上一开始只有一个基本块了，以及（如果程序运行的完）内存消耗被极大程度的控制住了。后者除了我们避免了一些`If`的展开以外，还是因为我们默默地复用了大量的基本块——有些复制只存在与逻辑上，实际上我们使用的是同一个对象的引用，并尽可能地坚持到了最后一刻。

然而，我们还有一个坏消息：优化过程依然久到无法接受。对优化过程的profile表明，99%以上的时间都花在了分支重定位的过程中，对这个算法所在的方法的调用次数是及其惊人的：在对一个大约实现了70%的TCP程序进行优化时，优化程序在其运行的十几秒之内调用了这个方法超过一千万次。

降低调用次数是提高性能的一种办法，不过在此之前我决定先采用另一种难度较低的办法：profile还显示，50%左右的计算时间都花在了分支重定位的第一步：构建读写依赖关系上。如果能提高依赖关系维护算法的性能，也能对于提升整体性能作出很大的帮助。

----

让我们来复习以下分支重定位算法的流程吧。首先我们需要分析当前基本块中各指令以及最后的判断条件的读写依赖关系，从而将所有的指令分成两种：必须在判断条件执行以前执行的，和什么时候执行无所谓的。然后，将后一种指令从当前基本块中「抽」出来，分别塞进后续的两个基本块的最开始，然后对后续的两个基本块递归地执行同样的算法。

哪些指令必须在判断条件之前执行呢？一种情况是这条指令被怕判断条件以某种方式依赖（读后写、写后读、写后写），考虑到判断条件只读不写，因此事实上只有写入了判定条件会读取的寄存器的指令才会被判断条件「直接」依赖。另一个「间接」依赖的情况自然就是以某种方式被另一条判断条件（直接或者间接）依赖的指令依赖，因此依赖的定义其实是递归的。

> 在开始看下一段之前：不要因为看到「最初的」就觉得现在没用了哦，在未来它又有用了。

我最初的读写依赖算法的原理是从前往后地「模拟」基本块的执行过程。在模拟的过程中，我维护了一个表格，它记录了每一个寄存器的**当前值**（到此为止）被哪些指令读取过，以及这个**当前值**又是被哪一条指令写入的。（后来，基本块中出现了`If`这样一种「有可能写也有可能不写」一个寄存器的指令，因此我不得不在表格中改为记录每个寄存器的当前值「有可能」是被哪些指令写入的，以及在每种写入情况下读取了当前值的指令的并集。）

当我分析一条指令时，对于这条指令写入的每一个寄存器，我可以得知这条指令必须晚于这个表格中关于这个寄存器的所有指令执行——无论是读了还是写了当前值的指令，因为读后写和写后写规则都存在。而对于这条指令读取的每一个寄存器，这条指令必须晚于每一条可能写入了这个寄存器当前值的指令执行——因为写后读。接下来，我们再根据这条指令的行为更新寄存器当前值的表格。对于当前指令读取的每一个寄存器，我们将它添加到读取这个寄存器的指令列表中去。如果我们知道这条指令一定会更新寄存器的当前值（`SetValue`和`Command`），那么我们就可以**清空有关于这个寄存器的所有信息**，只留下当前指令作为唯一的写入者；否则，对于`If`这种可能写入的指令，我们只能将它添加到写入嫌疑人的名单中。注意：**对表格的更新必须按照先读后写的顺序！**因为一条指令有可能读写同一个寄存器。

> 什么？你问我为什么这么激动？因此我写下上面这段话的时候才跑回去把程序改成正确的顺序……请各位也务必试试写博客调试法。

上面这种算法的好处有：
* 思路比较直观，作为原型实现比较合适
* 除了我们所需要的判定条件的依赖以外，其实我们还把**每一条指令依赖的指令**都给找到了，这也是它后来得以复活的原因

这种算法的缺点是：
* 它只能计算出每一条指令（和条件判断）的直接依赖，因此我们最后还需要一次遍历来求出条件判断的所有依赖指令
* 它不能使我们便利地发现潜在的`Choice`。当我们分析一个`If`的时候，我们还不知道条件判断是不是依赖于它，因此只能暂时放过它，等到所有依赖分析都完成了再回来，如果这个`If`真的是`Choice`的话就会使我们白做大量的工作。

----

基于上面的理由，我将这种算法重写为了以下的反向依赖维护算法。反向算法从条件判断出发，从后往前遍历基本块中的每一条指令，并且判断它是不是直接或者间接地被条件判断所依赖。我们同样需要维护有关于寄存器的信息，不过这回我们不需要一张表了，只需要两个集合：条件判断和它所依赖的所有指令需要读和写的寄存器集合。

在分析每一条指令时，判断它是不是条件判断的依赖的过程其实和上一种算法类似，只是需要将思路翻转一下：如果当前指令写的寄存器存在于读或者写的集合中（写后读/写后写），或者当前指令读的寄存器存在于写集合中（读后写），那么当前指令也是条件判断的依赖。

接下来，对于读写寄存器集合的更新，就比较不直观了：
* 如果当前指令是条件判断的依赖，那么将当前指令读/写的寄存器分别加入读/写集合中。
  * **如果当前指令一定会写一个寄存器（`SetValue`），那么将其从读集合中删除（如果它在读集合中）。**
* **如果当前指令不是条件判断的依赖，并且一定会写一个寄存器，那么将其从写集合中删除。**

让我们来分析一下「一定会写」意味着什么。它代表着当前值的终结——反向视角的终结，也就是前向视角的开始。当一条依赖指令「终结」了某个寄存器的当前值以后，执行顺序在其后的其他已知的依赖指令所读取的就不再是这个寄存器（在当前指令进行赋值操作之前）的当前值了。因此，这个寄存器就不再应该存在于读集合中。对于非依赖指令的分析过程与之类似。

但是，这样看似复杂的规则，实际上是可以简化的！

首先，如果当前指令不是条件判断的依赖，它所要写的寄存器一定不在写集合中，否则它就成为依赖了。因此，更新规则中的第二条，实际上是一句废话，永远不会执行。

如果没有了第二条规则，那么就没有机会从写集合中删除寄存器了。

然后再来考虑第一条规则的补充。如果一个寄存器被从读集合中删除，那么当前指令一定会写它，那么它一定存在于写集合中，并且由于写集合的单调膨胀，它一定会一直在写集合中存在下去。仔细推理一下依赖指令的判定规则，你会发现，一个只存在于写集合中的寄存器和在两个集合中都存在的寄存器实际上发挥的作用是一样的——都是让读写它的指令都成为依赖指令。因此，我们大可不将其从读集合中删除，而不会影响算法的运行结果。

这样一来，反向算法将会在运行效率上比前向算法提升一个台阶，而代价也就是「看起来好像不太对劲」而已。（

除此之外，反向算法可以在分析每一条指令的时候就判断出它是不是一条被条件判断依赖的指令，这使得我们可以在遇到一条被依赖的`If`时，有机会扔下手头的工作（指抛异常），立马开始展开工作。这也使得我们的工作量进一步减少。

## 总结

这篇文章提出了基本块惰性展开和读写依赖的反向维护算法两个优化思路。这对我们的优化程序产生了从0到1的提升效果——它终于能跑完了。但是这显然还不能令人满意。

我们会在下一篇文章中继续尝试进一步的优化技巧。那么这篇文章的内容是不是就没有用了呢？很不幸，无论是这篇文章还是有关这个话题中的任何一篇文章，凡是被我写下来的思路，最后都留在了（撰写文章时的）代码中继续发光发热。