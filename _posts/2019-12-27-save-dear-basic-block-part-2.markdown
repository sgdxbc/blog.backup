---
title: 拯救基本块大冒险！第二话
date: 2019-12-27 13:01
categories: weaver
tags: Python 优化 算法
toc: true
---

这次我们将直面问题的根源：将时间占比高达99.8%的条件分支重定位所承担的工作减轻。那么这么工作怎么办？自然是交给做起这些工作更顺手的「人」做完成。所谓优化，不就是「将原本职责清楚分工明确的代码搅成一团浆糊，从而减轻分工带来的信息共享损失而提高工作的效率」么。

## 后向预扫描

为什么分支定位要被调用那么多次呢？一个主要原因在于它承担了发现`Choice`的工作。如果我们可以在进行分支定位之前，先「尽可能」地发现一些`Choice`，并且将它们都融入基本块的结构中，使其对分支定位算法透明化，那么就可以大大减轻分支定位的工作量。

于是，我们可以在什么时候「发现」这些`Choice`呢？时机其实只有一个，那就是在构建基本块之前。在构建基本块之前，我们需要先遍历输入的指令序列，将其中的某些`If`对象替换为`Choice`。接下来构建基本块的时候，只有遇到了`Choice`才切断当前基本块，而把`If`当作是普通的指令。

如果你看文章足够仔细（记性也很好），你也许会想起来，这个预扫描步骤似乎早就已经存在了。没错，原本的预扫描仅仅是找出所有含有作为优化目标而被打了标记的命令所在的`If`块，然而现在这并不能满足我们了，我们还需要找出更多的`Choice`。为了便于描述，我们将包含了被打标记的命令而成为`Choice`的`If`称为「原生`Choice`」，而原本来仰赖分支定位算法中途发现的`Choice`称为「派生`Choice`」。

----

假如我们现在在一列指令中发现了一个原生`Choice`，那么谁会是派生`Choice`呢？这个答案我在上一篇文章中已经举例论证过了，就是那些作为原生`Choice`依赖的`If`指令。那么我们要怎么直到原生`Choice`依赖于哪些`If`呢？答案就是读写依赖的前向维护算法。还记得它那条重要的优点吗？「顺便求出了基本块中每一条指令的依赖。」虽然我们现在不是在基本块结构中了，但是我们依然需要指令序列中每一条指令的依赖信息，因为`Choice`有可能出现在指令序列中的任意位置。这就是我把前向算法从垃圾堆里捡回来的故事。

这样一来，「后向预扫描」中的「后向」也就好理解了。对于一个指令序列，我们从后向前的扫描它的每一条指令，如果发现了一条`If`，那么首先确定它是不是原生`Choice`，如果不是，再看看它是否被它后面的`Choice`依赖，如果有被依赖，那么它就是派生`Choice`。每当发现了一条`Choice`，我们就根据其依赖信息，更新其前方各指令被依赖情况，这样等那些指令被扫描到的时候就可以方便地确定它有没有被依赖了。

作为这个算法的最后一部分，我们来考察一下平行`If`的情形。如果后一个`If`是一个原生`Choice`，而前一个`If`是一个派生`Choice`，那么我们的确可以在当前指令序列中正确地将它们替换为`Choice`。然而，当我们对前一个`If`的两个分支指令序列进行遍历时，我们将不会找到这个大派生`Choice`内部的任何小派生`Choice`，因为我们已经失去了有关于上一层中靠后的原生`Choice`的一切信息。为了解决这个问题，在递归地进入分支指令序列时，我们同时传入一个凭空捏造出来的`Value`，并且它读取后方原生`Choice`读取的所有寄存器。刚好，我们从垃圾堆里捡回来的依赖维护算法可以在指令序列之外再接受一个值作为参数——这原来是为基本块的条件判断值设计的……

如此一来，我们的后向预扫描算法基本完成了，在进一步讨论之前，我决定先摘录它的一段逻辑着重说明

```python
    for i in (j - 1 for j in range(len(codes), 0, -1)):
        instr = codes[i]
        if isinstance(instr, Command) and instr.opt_target:
            choice = True
            agg_choice = Value(list(set(agg_choice.regs + instr.read_regs)))
        if isinstance(instr, If):
            scanned_yes, choice_yes = BasicBlock.scan_codes(instr.yes, agg_choice)
            scanned_no, choice_no = BasicBlock.scan_codes(instr.no, agg_choice)
            if choice_yes or choice_no:
                choice = True
                agg_choice = Value(list(set(agg_choice.regs + instr.read_regs)))
            if choice_yes or choice_no or choice_instr[instr]:
                for dep_instr in dep_graph[instr]:
                    choice_instr[dep_instr] = True
                scanned[i] = Choice(instr.cond, scanned_yes, scanned_no)
            else:
                scanned[i] = instr
        else:
            if choice_instr[instr]:
                for dep_instr in dep_graph[instr]:
                    choice_instr[dep_instr] = True
            scanned[i] = instr
    return scanned, choice
```

后向遍历到每一条指令时，首先判断它是不是被打了标记的命令；如果是，那么我们正在遍历的就是一个原生`Choice`的一条分支。此外，如果这是一条`If`指令，就递归遍历它的两个子分支，如果其中任何一个是原生`Choice`所在的分支，那么我们也是原生`Choice`的一个分支。当我们也处在原生`Choice`当中的时候，将`choice`设置为`True`，并且调整伪造的值`agg_value`所读取的寄存器列表。接下来，无论我们在看的是原生`Choice`还是派生`Choice`，都将从`If`转变为`Choice`，并将它依赖的指令设置为派生`Choice`。最后，如果我们遇到的是一条被当作`Choice`的普通指令，那么也同样将它依赖的指令设置为`Choice`。

这组逻辑中最重要的一点就是**派生`Choice`的依赖不会被向前传递**。这会使我们有机会漏掉前方子分支中的`Choice`。比如

```c
if (x == 0) {
    if (x == 0) {
        y = 1;
    }
    if (x == 0) {
        q = 0;
    }
}
if (y == 1) {
    // w = q;
    z = 0;
}
if (z == 0) {
    Create();
}
```

首先我们发现了最后一个`If`是一个原生`Choice`，并且根据它的依赖（递归地）发现前面两个`If`都是派生`Choice`。但是，在我们开始遍历第一个`If`的子序列时，伪造的值`agg_value`依然只会依赖于`z`，因此第一个`If`中的第一个`If`是一个被我们忽略了的`Choice`。

那么，为什么不考虑派生`Choice`的依赖呢？这是因为像`Choice`这样的复合语句的依赖信息实在太笼统了。如果第二个`If`中注释掉的`w = q`被打开的话，那么这两个寄存器也会成为第二个`If`的依赖，如果我们也将它们纳入考察的范围内，就会导致我们错误地将第一个`If`中的第二个`If`也判定为派生`Choice`，造成不必要的展开。如果再考虑到条件分支实际上（最多）只会执行其中一条分支，而我们却假设了它会读写所有两条分支上涉及的寄存器的话，这种模糊信息造成的误判就会大量增加。一定要记住，如果在这里没有展开一个应该展开的`If`，那么到了分支定位的时候我们还有机会；但是一旦把一个不需要展开的`If`给展开了，那么增加的基本块所浪费的时间和内存就再也没机会拿回来了。

## 常量分析

在增加了预扫描步骤以后，热点一下就转移到了递归构建基本块的过程中来了。看来，虽然我们已经故意忽略了一些`Choice`，剩下的`Choice`还是太多了。作为最后一根救命稻草，我们的算法中还有一个步骤有可能减少条件分支（以及基本块）的数目，那就是常量分析。所以，我再次推迟了展开`Choice`的时机，在预扫描后，对惰性展开的基本块执行常量分析和构造基本块叠加起来的操作：如果一个`If`（或者`Choice`）的条件判断值可以静态确定，那么直接用它的一个分支代替它；如果不可以确定，而它又是一个`Choice`，那么我们就不得不就地展开它。相比起在分支定位阶段就地展开，常量分析阶段牵扯到的相关工作基本没有，因此也不会浪费什么工作量。

到了这里，我们的故事终于迎来了喜闻乐见的大团圆结局：一个100%实现的TCP协议可以在0.3s以内完成优化，至于它使用的内存量自然也不用担心了。

## 总结

本篇文章继续介绍了两次转移工作量的操作，逐渐将原本压在条件定位算法上的重担换到了更适合的环节中去。在这个系列的下一篇文章中，我会补充一些细节，并且发表一段后日谈性质的感想。